{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('AB_NYC_2019.csv')\n",
    "\n",
    "# 1. Data Integrity\n",
    "\n",
    "# Convert `last_review` to datetime\n",
    "df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'name':\n",
      " ['clean & quiet apt home by the park' 'skylit midtown castle'\n",
      " 'the village of harlem....new york !' ...\n",
      " 'sunny studio at historical neighborhood'\n",
      " '43rd st. time square-cozy single bed'\n",
      " \"trendy duplex in the very heart of hell's kitchen\"]\n",
      "Unique values in 'host_name':\n",
      " ['john' 'jennifer' 'elisabeth' ... 'abayomi' 'alberth' 'ilgar & aysel']\n",
      "Unique values in 'neighbourhood_group':\n",
      " ['brooklyn' 'manhattan' 'queens' 'staten island' 'bronx']\n",
      "Unique values in 'neighbourhood':\n",
      " ['kensington' 'midtown' 'harlem' 'clinton hill' 'east harlem'\n",
      " 'murray hill' 'bedford-stuyvesant' \"hell's kitchen\" 'upper west side'\n",
      " 'chinatown' 'south slope' 'west village' 'williamsburg' 'fort greene'\n",
      " 'chelsea' 'crown heights' 'park slope' 'windsor terrace' 'inwood'\n",
      " 'east village' 'greenpoint' 'bushwick' 'flatbush' 'lower east side'\n",
      " 'prospect-lefferts gardens' 'long island city' 'kips bay' 'soho'\n",
      " 'upper east side' 'prospect heights' 'washington heights' 'woodside'\n",
      " 'brooklyn heights' 'carroll gardens' 'gowanus' 'flatlands' 'cobble hill'\n",
      " 'flushing' 'boerum hill' 'sunnyside' 'dumbo' 'st. george' 'highbridge'\n",
      " 'financial district' 'ridgewood' 'morningside heights' 'jamaica'\n",
      " 'middle village' 'noho' 'ditmars steinway' 'flatiron district'\n",
      " 'roosevelt island' 'greenwich village' 'little italy' 'east flatbush'\n",
      " 'tompkinsville' 'astoria' 'clason point' 'eastchester' 'kingsbridge'\n",
      " 'two bridges' 'queens village' 'rockaway beach' 'forest hills' 'nolita'\n",
      " 'woodlawn' 'university heights' 'gravesend' 'gramercy' 'allerton'\n",
      " 'east new york' 'theater district' 'concourse village' 'sheepshead bay'\n",
      " 'emerson hill' 'fort hamilton' 'bensonhurst' 'tribeca' 'shore acres'\n",
      " 'sunset park' 'concourse' 'elmhurst' 'brighton beach' 'jackson heights'\n",
      " 'cypress hills' 'st. albans' 'arrochar' 'rego park' 'wakefield' 'clifton'\n",
      " 'bay ridge' 'graniteville' 'spuyten duyvil' 'stapleton' 'briarwood'\n",
      " 'ozone park' 'columbia st' 'vinegar hill' 'mott haven' 'longwood'\n",
      " 'canarsie' 'battery park city' 'civic center' 'east elmhurst'\n",
      " 'new springville' 'morris heights' 'arverne' 'cambria heights'\n",
      " 'tottenville' 'mariners harbor' 'concord' 'borough park' 'bayside'\n",
      " 'downtown brooklyn' 'port morris' 'fieldston' 'kew gardens' 'midwood'\n",
      " 'college point' 'mount eden' 'city island' 'glendale' 'port richmond'\n",
      " 'red hook' 'richmond hill' 'bellerose' 'maspeth' 'williamsbridge'\n",
      " 'soundview' 'woodhaven' 'woodrow' 'co-op city' 'stuyvesant town'\n",
      " 'parkchester' 'north riverdale' 'dyker heights' 'bronxdale' 'sea gate'\n",
      " 'riverdale' 'kew gardens hills' 'bay terrace' 'norwood'\n",
      " 'claremont village' 'whitestone' 'fordham' 'bayswater' 'navy yard'\n",
      " 'brownsville' 'eltingville' 'fresh meadows' 'mount hope'\n",
      " 'lighthouse hill' 'springfield gardens' 'howard beach' 'belle harbor'\n",
      " 'jamaica estates' 'van nest' 'morris park' 'west brighton' 'far rockaway'\n",
      " 'south ozone park' 'tremont' 'corona' 'great kills' 'manhattan beach'\n",
      " 'marble hill' 'dongan hills' 'castleton corners' 'east morrisania'\n",
      " 'hunts point' 'neponsit' 'pelham bay' 'randall manor' 'throgs neck'\n",
      " 'todt hill' 'west farms' 'silver lake' 'morrisania' 'laurelton'\n",
      " 'grymes hill' 'holliswood' 'pelham gardens' 'belmont' 'rosedale'\n",
      " 'edgemere' 'new brighton' 'midland beach' 'baychester' 'melrose'\n",
      " 'bergen beach' 'richmondtown' 'howland hook' 'schuylerville'\n",
      " 'coney island' 'new dorp beach' \"prince's bay\" 'south beach' 'bath beach'\n",
      " 'jamaica hills' 'oakwood' 'castle hill' 'hollis' 'douglaston' 'huguenot'\n",
      " 'olinville' 'edenwald' 'grant city' 'westerleigh'\n",
      " 'bay terrace, staten island' 'westchester square' 'little neck'\n",
      " 'fort wadsworth' 'rosebank' 'unionport' 'mill basin' 'arden heights'\n",
      " \"bull's head\" 'new dorp' 'rossville' 'breezy point' 'willowbrook']\n",
      "Unique values in 'room_type':\n",
      " ['private room' 'entire home/apt' 'shared room']\n"
     ]
    }
   ],
   "source": [
    "# Convert numeric columns to appropriate types\n",
    "numeric_columns = [\n",
    "    'id', 'host_id', 'latitude', 'longitude', 'price', \n",
    "    'minimum_nights', 'number_of_reviews', 'reviews_per_month', \n",
    "    'calculated_host_listings_count', 'availability_365'\n",
    "]\n",
    "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Verify categorical fields contain valid and expected values\n",
    "# Convert categorical fields to lowercase and strip any extra spaces\n",
    "categorical_columns = [\n",
    "    'name', 'host_name', 'neighbourhood_group', 'neighbourhood', 'room_type'\n",
    "]\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: x.str.lower().str.strip())\n",
    "\n",
    "# Check for unique values in categorical fields\n",
    "for col in categorical_columns:\n",
    "    print(f\"Unique values in '{col}':\\n\", df[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      " id                                    0\n",
      "name                                 16\n",
      "host_id                               0\n",
      "host_name                            21\n",
      "neighbourhood_group                   0\n",
      "neighbourhood                         0\n",
      "latitude                              0\n",
      "longitude                             0\n",
      "room_type                             0\n",
      "price                                 0\n",
      "minimum_nights                        0\n",
      "number_of_reviews                     0\n",
      "last_review                       10052\n",
      "reviews_per_month                 10052\n",
      "calculated_host_listings_count        0\n",
      "availability_365                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Missing Data Handling\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values before handling:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANKIT\\AppData\\Local\\Temp\\ipykernel_10720\\806112462.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviews_per_month'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define strategies for handling missing values\n",
    "# Fill missing values in `reviews_per_month` with 0 (assuming no reviews means 0 reviews per month)\n",
    "df['reviews_per_month'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANKIT\\AppData\\Local\\Temp\\ipykernel_10720\\3883386831.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['last_review'].fillna(earliest_review_date, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in `last_review` with the earliest review date in the dataset\n",
    "# If 'last_review' column has missing values, fill them with the earliest review date\n",
    "if df['last_review'].isnull().any():\n",
    "    earliest_review_date = df['last_review'].min()\n",
    "    df['last_review'].fillna(earliest_review_date, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values in critical fields\n",
    "df.dropna(subset=['name', 'host_name', 'neighbourhood_group', 'neighbourhood', 'latitude', 'longitude', 'room_type', 'price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after handling:\n",
      " id                                0\n",
      "name                              0\n",
      "host_id                           0\n",
      "host_name                         0\n",
      "neighbourhood_group               0\n",
      "neighbourhood                     0\n",
      "latitude                          0\n",
      "longitude                         0\n",
      "room_type                         0\n",
      "price                             0\n",
      "minimum_nights                    0\n",
      "number_of_reviews                 0\n",
      "last_review                       0\n",
      "reviews_per_month                 0\n",
      "calculated_host_listings_count    0\n",
      "availability_365                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values after handling\n",
    "missing_values_after = df.isnull().sum()\n",
    "print(\"Missing values after handling:\\n\", missing_values_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# 3. Duplicate Removal\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_rows = df.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df_cleaned = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows after removal: 0\n"
     ]
    }
   ],
   "source": [
    "# Verify that duplicates have been removed\n",
    "duplicate_rows_after = df_cleaned.duplicated()\n",
    "print(f\"Number of duplicate rows after removal: {duplicate_rows_after.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Standardization\n",
    "\n",
    "# Standardize text fields: Convert to lowercase and strip extra spaces\n",
    "text_fields = ['name', 'host_name', 'neighbourhood_group', 'neighbourhood', 'room_type']\n",
    "df[text_fields] = df[text_fields].apply(lambda x: x.str.lower().str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric fields are within realistic ranges\n",
    "# Example checks for latitude and longitude ranges\n",
    "df = df[(df['latitude'] >= -90) & (df['latitude'] <= 90)]\n",
    "df = df[(df['longitude'] >= -180) & (df['longitude'] <= 180)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure prices are positive and reasonable (assuming a max price of 10,000 for this example)\n",
    "df = df[df['price'] > 0]\n",
    "df = df[df['price'] <= 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `minimum_nights` is positive\n",
    "df = df[df['minimum_nights'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize date formats\n",
    "df['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Outlier Detection\n",
    "\n",
    "# Function to detect outliers using Z-score method\n",
    "def detect_outliers_zscore(data, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(data))\n",
    "    return np.where(z_scores > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in numeric columns and address them\n",
    "numeric_columns = ['price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store the indices of outliers\n",
    "outliers_indices = pd.DataFrame()\n",
    "\n",
    "for column in numeric_columns:\n",
    "    outliers = detect_outliers_zscore(df[column].dropna())\n",
    "    outliers_indices[column] = pd.Series(outliers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers removed in 'price': 388\n",
      "Outliers removed in 'minimum_nights': 327\n",
      "Outliers removed in 'number_of_reviews': 388\n",
      "Outliers removed in 'reviews_per_month': 388\n",
      "Outliers removed in 'calculated_host_listings_count': 388\n",
      "Outliers removed in 'availability_365': 0\n"
     ]
    }
   ],
   "source": [
    "# Verify if outliers are removed\n",
    "for column in numeric_columns:\n",
    "    print(f\"Outliers removed in '{column}': {outliers_indices[column].dropna().size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

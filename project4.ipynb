{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ANKIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ANKIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ANKIT\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  category  \\\n",
      "0  when modi promised minimum government maximum ...      -1.0   \n",
      "1  talk all the nonsense and continue all the dra...       0.0   \n",
      "2  what did just say vote for modi welcome bjp to...       1.0   \n",
      "3  asking his supporters prefix chowkidar their n...       1.0   \n",
      "4  answer who among these the most powerful world...       1.0   \n",
      "\n",
      "   predicted_category  \n",
      "0                  -1  \n",
      "1                   0  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Ensure the required NLTK data is downloaded\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Load data from CSV file\n",
    "file_path = 'Twitter_Data.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Sentiment Analysis\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Ensure the entry is a string\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'\\@\\w+|\\#', '', text)  # Remove mentions and hashtags\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and numbers\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "        return text\n",
    "    else:\n",
    "        return \"\"  # Return empty string for non-string entries\n",
    "\n",
    "# Apply cleaning function to the text data\n",
    "df['clean_text'] = df['clean_text'].apply(clean_text)\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        return 1\n",
    "    elif sentiment < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df['predicted_category'] = df['clean_text'].apply(get_sentiment)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  category  \\\n",
      "0  modi promised minimum government maximum gover...      -1.0   \n",
      "1             talk nonsense continue drama vote modi       0.0   \n",
      "2  say vote modi welcome bjp told rahul main camp...       1.0   \n",
      "3  asking supporter prefix chowkidar name modi gr...       1.0   \n",
      "4  answer among powerful world leader today trump...       1.0   \n",
      "\n",
      "   predicted_category  \n",
      "0                  -1  \n",
      "1                   0  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n",
      "x-shape -  (162980, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Ensure the entry is a string\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'\\@\\w+|\\#', '', text)  # Remove mentions and hashtags\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and numbers\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "        \n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        \n",
    "        # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return \"\"  # Return empty string for non-string entries\n",
    "\n",
    "# Apply preprocessing function to the text data\n",
    "df['clean_text'] = df['clean_text'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "print(\"x-shape - \",X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming df['category'] contains the sentiment labels\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Split data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train Naive Bayes model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming df['category'] contains the sentiment labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
